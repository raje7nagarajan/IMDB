{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Add path to driver\n",
    "driver_path = r\"D:\\chromedriver-win64\\chromedriver.exe\"\n",
    "\n",
    "# Adding webdriver as service\n",
    "service = Service(executable_path=driver_path)  # Create a Service object\n",
    "driver = webdriver.Chrome(service=service)  # Pass the Service object\n",
    "driver.get(\"https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres=action\")\n",
    "\n",
    "# Initialize lists to store data\n",
    "movie_titles = []\n",
    "ratings = []\n",
    "votings = []\n",
    "durations = []\n",
    "genres = []\n",
    "# Set to keep track of already scraped movie titles to avoid duplicates\n",
    "scraped_titles = set()\n",
    "\n",
    "# Start the \"Load More\" click counter\n",
    "load_more_count = 0  # Initialize counter for Load More clicks\n",
    "\n",
    "# Loop to click \"Load More\" and scrape data 10 times\n",
    "while load_more_count < 15:\n",
    "    # Locate the base element containing the movie items\n",
    "    movie_base = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/ul/li')\n",
    "    \n",
    "    # Loop through each movie item and extract information\n",
    "    for movie_item in movie_base:\n",
    "        try:\n",
    "            # Extract movie details for each movie item\n",
    "            title = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/div[1]/a/h3').text\n",
    "            \n",
    "            # Skip the movie if we've already scraped it\n",
    "            if title in scraped_titles:\n",
    "                continue\n",
    "            \n",
    "            # Extract rating, voting, and duration\n",
    "            try:\n",
    "                rating = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/span/div/span/span[1]').text\n",
    "            except:\n",
    "                rating = None\n",
    "\n",
    "            try:\n",
    "                voting = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/span/div/span/span[2]').text\n",
    "            except:\n",
    "                voting = None\n",
    "\n",
    "            try:\n",
    "                duration = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/div[2]/span[2]').text\n",
    "            except:\n",
    "                duration = None\n",
    "\n",
    "            # Extract genre (as it's a single value here, ensure it's extracted correctly)\n",
    "            genre = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[1]/div/div/div[2]/button[3]/span').text\n",
    "\n",
    "            # Validate if essential fields (title, rating, voting, duration) are not empty\n",
    "            if title and rating and voting and duration:\n",
    "                movie_titles.append(title.split(\". \", 1)[1])  # Adjust title if needed\n",
    "                ratings.append(rating)\n",
    "                votings.append(voting)\n",
    "                durations.append(duration)\n",
    "                genres.append(genre)\n",
    "\n",
    "                # Add the title to the set of scraped titles to prevent duplicates\n",
    "                scraped_titles.add(title)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error while scraping the data:\", e)\n",
    "            continue\n",
    "\n",
    "    # Try to click the \"Load More\" button and increment counter\n",
    "    try:\n",
    "        # Find the \"Load More\" button (Next button)\n",
    "        next_button = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/div[2]/div/span')\n",
    "\n",
    "        # Perform the action to hover over and click the \"Load More\" button\n",
    "        ActionChains(driver).move_to_element(next_button).perform()\n",
    "        next_button.click()\n",
    "\n",
    "        # Increment the counter\n",
    "        load_more_count += 1\n",
    "\n",
    "        # Wait for 3 seconds to allow more movies to load\n",
    "        time.sleep(3)\n",
    "    except Exception as e:\n",
    "        print(\"Error in load more option\", e)\n",
    "        break  # Exit the loop if the button cannot be found or clicked\n",
    "\n",
    "# Close the browser after scraping\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame from the scraped data\n",
    "final_data_action = pd.DataFrame({\n",
    "    'Movie Title': movie_titles,\n",
    "    'Movie Rating': ratings,\n",
    "    'Movie Votings': votings,\n",
    "    'Movie Durations': durations,\n",
    "    'Genres': genres\n",
    "})\n",
    "\n",
    "# Save the data to a CSV file\n",
    "final_data_action.to_csv(r'D:\\DA\\IMDB_2024_action.csv', index=False)\n",
    "\n",
    "print(\"Scraping finished and data saved to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping finished and data saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Add path to driver\n",
    "driver_path = r\"D:\\chromedriver-win64\\chromedriver.exe\"\n",
    "\n",
    "# Adding webdriver as service\n",
    "service = Service(executable_path=driver_path)  # Create a Service object\n",
    "driver = webdriver.Chrome(service=service)  # Pass the Service object\n",
    "driver.get(\"https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres=animation\")\n",
    "\n",
    "# Initialize lists to store data\n",
    "movie_titles = []\n",
    "ratings = []\n",
    "votings = []\n",
    "durations = []\n",
    "genres = []\n",
    "# Set to keep track of already scraped movie titles to avoid duplicates\n",
    "scraped_titles = set()\n",
    "\n",
    "# Start the \"Load More\" click counter\n",
    "load_more_count = 0  # Initialize counter for Load More clicks\n",
    "\n",
    "# Loop to click \"Load More\" and scrape data\n",
    "while load_more_count < 8:\n",
    "    # Locate the base element containing the movie items\n",
    "    movie_base = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/ul/li')\n",
    "    \n",
    "    # Loop through each movie item and extract information\n",
    "    for movie_item in movie_base:\n",
    "        try:\n",
    "            # Extract movie details for each movie item\n",
    "            title = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/div[1]/a/h3').text\n",
    "            \n",
    "            # Skip the movie if we've already scraped it\n",
    "            if title in scraped_titles:\n",
    "                continue\n",
    "            \n",
    "            # Extract rating, voting, and duration\n",
    "            try:\n",
    "                rating = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/span/div/span/span[1]').text\n",
    "            except:\n",
    "                rating = None\n",
    "\n",
    "            try:\n",
    "                voting = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/span/div/span/span[2]').text\n",
    "            except:\n",
    "                voting = None\n",
    "\n",
    "            try:\n",
    "                duration = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/div[2]/span[2]').text\n",
    "            except:\n",
    "                duration = None\n",
    "\n",
    "            # Extract genre (as it's a single value here, ensure it's extracted correctly)\n",
    "            genre = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[1]/div/div/div[2]/button[3]/span').text\n",
    "\n",
    "            # Validate if essential fields (title, rating, voting, duration) are not empty\n",
    "            if title and rating and voting and duration:\n",
    "                movie_titles.append(title.split(\". \", 1)[1])  # Adjust title if needed\n",
    "                ratings.append(rating)\n",
    "                votings.append(voting)\n",
    "                durations.append(duration)\n",
    "                genres.append(genre)\n",
    "\n",
    "                # Add the title to the set of scraped titles to prevent duplicates\n",
    "                scraped_titles.add(title)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error while scraping the data:\", e)\n",
    "            continue\n",
    "\n",
    "    # Try to click the \"Load More\" button and increment counter\n",
    "    try:\n",
    "        # Find the \"Load More\" button (Next button)\n",
    "        next_button = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/div[2]/div/span')\n",
    "\n",
    "        # Perform the action to hover over and click the \"Load More\" button\n",
    "        ActionChains(driver).move_to_element(next_button).perform()\n",
    "        next_button.click()\n",
    "\n",
    "        # Increment the counter\n",
    "        load_more_count += 1\n",
    "\n",
    "        # Wait for 3 seconds to allow more movies to load\n",
    "        time.sleep(3)\n",
    "    except Exception as e:\n",
    "        print(\"Error in load more option\", e)\n",
    "        break  # Exit the loop if the button cannot be found or clicked\n",
    "\n",
    "# Close the browser after scraping\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame from the scraped data\n",
    "final_data_action = pd.DataFrame({\n",
    "    'Movie Title': movie_titles,\n",
    "    'Movie Rating': ratings,\n",
    "    'Movie Votings': votings,\n",
    "    'Movie Durations': durations,\n",
    "    'Genres': genres\n",
    "})\n",
    "\n",
    "# Save the data to a CSV file\n",
    "final_data_action.to_csv(r'D:\\DA\\IMDB_2024_animation.csv', index=False)\n",
    "\n",
    "print(\"Scraping finished and data saved to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping finished and data saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Add path to driver\n",
    "driver_path = r\"D:\\chromedriver-win64\\chromedriver.exe\"\n",
    "\n",
    "# Adding webdriver as service\n",
    "service = Service(executable_path=driver_path)  # Create a Service object\n",
    "driver = webdriver.Chrome(service=service)  # Pass the Service object\n",
    "driver.get(\"https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres=family\")\n",
    "\n",
    "# Initialize lists to store data\n",
    "movie_titles = []\n",
    "ratings = []\n",
    "votings = []\n",
    "durations = []\n",
    "genres = []\n",
    "# Set to keep track of already scraped movie titles to avoid duplicates\n",
    "scraped_titles = set()\n",
    "\n",
    "# Start the \"Load More\" click counter\n",
    "load_more_count = 0  # Initialize counter for Load More clicks\n",
    "\n",
    "# Loop to click \"Load More\" and scrape data 10 times\n",
    "while load_more_count < 10:\n",
    "    # Locate the base element containing the movie items\n",
    "    movie_base = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/ul/li')\n",
    "    \n",
    "    # Loop through each movie item and extract information\n",
    "    for movie_item in movie_base:\n",
    "        try:\n",
    "            # Extract movie details for each movie item\n",
    "            title = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/div[1]/a/h3').text\n",
    "            \n",
    "            # Skip the movie if we've already scraped it\n",
    "            if title in scraped_titles:\n",
    "                continue\n",
    "            \n",
    "            # Extract rating, voting, and duration\n",
    "            try:\n",
    "                rating = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/span/div/span/span[1]').text\n",
    "            except:\n",
    "                rating = None\n",
    "\n",
    "            try:\n",
    "                voting = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/span/div/span/span[2]').text\n",
    "            except:\n",
    "                voting = None\n",
    "\n",
    "            try:\n",
    "                duration = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/div[2]/span[2]').text\n",
    "            except:\n",
    "                duration = None\n",
    "\n",
    "            # Extract genre (as it's a single value here, ensure it's extracted correctly)\n",
    "            genre = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[1]/div/div/div[2]/button[3]/span').text\n",
    "\n",
    "            # Validate if essential fields (title, rating, voting, duration) are not empty\n",
    "            if title and rating and voting and duration:\n",
    "                movie_titles.append(title.split(\". \", 1)[1])  # Adjust title if needed\n",
    "                ratings.append(rating)\n",
    "                votings.append(voting)\n",
    "                durations.append(duration)\n",
    "                genres.append(genre)\n",
    "\n",
    "                # Add the title to the set of scraped titles to prevent duplicates\n",
    "                scraped_titles.add(title)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error while scraping the data:\", e)\n",
    "            continue\n",
    "\n",
    "    # Try to click the \"Load More\" button and increment counter\n",
    "    try:\n",
    "        # Find the \"Load More\" button (Next button)\n",
    "        next_button = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/div[2]/div/span')\n",
    "\n",
    "        # Perform the action to hover over and click the \"Load More\" button\n",
    "        ActionChains(driver).move_to_element(next_button).perform()\n",
    "        next_button.click()\n",
    "\n",
    "        # Increment the counter\n",
    "        load_more_count += 1\n",
    "\n",
    "        # Wait for 3 seconds to allow more movies to load\n",
    "        time.sleep(3)\n",
    "    except Exception as e:\n",
    "        print(\"Error in load more option\", e)\n",
    "        break  # Exit the loop if the button cannot be found or clicked\n",
    "\n",
    "# Close the browser after scraping\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame from the scraped data\n",
    "final_data_action = pd.DataFrame({\n",
    "    'Movie Title': movie_titles,\n",
    "    'Movie Rating': ratings,\n",
    "    'Movie Votings': votings,\n",
    "    'Movie Durations': durations,\n",
    "    'Genres': genres\n",
    "})\n",
    "\n",
    "# Save the data to a CSV file\n",
    "final_data_action.to_csv(r'D:\\DA\\IMDB_2024_family.csv', index=False)\n",
    "\n",
    "print(\"Scraping finished and data saved to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping finished and data saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Add path to driver\n",
    "driver_path = r\"D:\\chromedriver-win64\\chromedriver.exe\"\n",
    "\n",
    "# Adding webdriver as service\n",
    "service = Service(executable_path=driver_path)  # Create a Service object\n",
    "driver = webdriver.Chrome(service=service)  # Pass the Service object\n",
    "driver.get(\"https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres=fantasy\")\n",
    "\n",
    "# Initialize lists to store data\n",
    "movie_titles = []\n",
    "ratings = []\n",
    "votings = []\n",
    "durations = []\n",
    "genres = []\n",
    "# Set to keep track of already scraped movie titles to avoid duplicates\n",
    "scraped_titles = set()\n",
    "\n",
    "# Start the \"Load More\" click counter\n",
    "load_more_count = 0  # Initialize counter for Load More clicks\n",
    "\n",
    "# Loop to click \"Load More\" and scrape data 10 times\n",
    "while load_more_count < 9:\n",
    "    # Locate the base element containing the movie items\n",
    "    movie_base = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/ul/li')\n",
    "    \n",
    "    # Loop through each movie item and extract information\n",
    "    for movie_item in movie_base:\n",
    "        try:\n",
    "            # Extract movie details for each movie item\n",
    "            title = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/div[1]/a/h3').text\n",
    "            \n",
    "            # Skip the movie if we've already scraped it\n",
    "            if title in scraped_titles:\n",
    "                continue\n",
    "            \n",
    "            # Extract rating, voting, and duration\n",
    "            try:\n",
    "                rating = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/span/div/span/span[1]').text\n",
    "            except:\n",
    "                rating = None\n",
    "\n",
    "            try:\n",
    "                voting = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/span/div/span/span[2]').text\n",
    "            except:\n",
    "                voting = None\n",
    "\n",
    "            try:\n",
    "                duration = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/div[2]/span[2]').text\n",
    "            except:\n",
    "                duration = None\n",
    "\n",
    "            # Extract genre (as it's a single value here, ensure it's extracted correctly)\n",
    "            genre = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[1]/div/div/div[2]/button[3]/span').text\n",
    "\n",
    "            # Validate if essential fields (title, rating, voting, duration) are not empty\n",
    "            if title and rating and voting and duration:\n",
    "                movie_titles.append(title.split(\". \", 1)[1])  # Adjust title if needed\n",
    "                ratings.append(rating)\n",
    "                votings.append(voting)\n",
    "                durations.append(duration)\n",
    "                genres.append(genre)\n",
    "\n",
    "                # Add the title to the set of scraped titles to prevent duplicates\n",
    "                scraped_titles.add(title)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error while scraping the data:\", e)\n",
    "            continue\n",
    "\n",
    "    # Try to click the \"Load More\" button and increment counter\n",
    "    try:\n",
    "        # Find the \"Load More\" button (Next button)\n",
    "        next_button = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/div[2]/div/span')\n",
    "\n",
    "        # Perform the action to hover over and click the \"Load More\" button\n",
    "        ActionChains(driver).move_to_element(next_button).perform()\n",
    "        next_button.click()\n",
    "\n",
    "        # Increment the counter\n",
    "        load_more_count += 1\n",
    "\n",
    "        # Wait for 3 seconds to allow more movies to load\n",
    "        time.sleep(3)\n",
    "    except Exception as e:\n",
    "        print(\"Error in load more option\", e)\n",
    "        break  # Exit the loop if the button cannot be found or clicked\n",
    "\n",
    "# Close the browser after scraping\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame from the scraped data\n",
    "final_data_action = pd.DataFrame({\n",
    "    'Movie Title': movie_titles,\n",
    "    'Movie Rating': ratings,\n",
    "    'Movie Votings': votings,\n",
    "    'Movie Durations': durations,\n",
    "    'Genres': genres\n",
    "})\n",
    "\n",
    "# Save the data to a CSV file\n",
    "final_data_action.to_csv(r'D:\\DA\\IMDB_2024_fantacy.csv', index=False)\n",
    "\n",
    "print(\"Scraping finished and data saved to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping finished and data saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Add path to driver\n",
    "driver_path = r\"D:\\chromedriver-win64\\chromedriver.exe\"\n",
    "\n",
    "# Adding webdriver as service\n",
    "service = Service(executable_path=driver_path)  # Create a Service object\n",
    "driver = webdriver.Chrome(service=service)  # Pass the Service object\n",
    "driver.get(\"https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres=sci-fi\")\n",
    "\n",
    "# Initialize lists to store data\n",
    "movie_titles = []\n",
    "ratings = []\n",
    "votings = []\n",
    "durations = []\n",
    "genres = []\n",
    "# Set to keep track of already scraped movie titles to avoid duplicates\n",
    "scraped_titles = set()\n",
    "\n",
    "# Start the \"Load More\" click counter\n",
    "load_more_count = 0  # Initialize counter for Load More clicks\n",
    "\n",
    "# Loop to click \"Load More\" and scrape data 10 times\n",
    "while load_more_count < 10:\n",
    "    # Locate the base element containing the movie items\n",
    "    movie_base = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/ul/li')\n",
    "    \n",
    "    # Loop through each movie item and extract information\n",
    "    for movie_item in movie_base:\n",
    "        try:\n",
    "            # Extract movie details for each movie item\n",
    "            title = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/div[1]/a/h3').text\n",
    "            \n",
    "            # Skip the movie if we've already scraped it\n",
    "            if title in scraped_titles:\n",
    "                continue\n",
    "            \n",
    "            # Extract rating, voting, and duration\n",
    "            try:\n",
    "                rating = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/span/div/span/span[1]').text\n",
    "            except:\n",
    "                rating = None\n",
    "\n",
    "            try:\n",
    "                voting = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/span/div/span/span[2]').text\n",
    "            except:\n",
    "                voting = None\n",
    "\n",
    "            try:\n",
    "                duration = movie_item.find_element(By.XPATH, './div/div/div/div[1]/div[2]/div[2]/span[2]').text\n",
    "            except:\n",
    "                duration = None\n",
    "\n",
    "            # Extract genre (as it's a single value here, ensure it's extracted correctly)\n",
    "            genre = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[1]/div/div/div[2]/button[3]/span').text\n",
    "\n",
    "            # Validate if essential fields (title, rating, voting, duration) are not empty\n",
    "            if title and rating and voting and duration:\n",
    "                movie_titles.append(title.split(\". \", 1)[1])  # Adjust title if needed\n",
    "                ratings.append(rating)\n",
    "                votings.append(voting)\n",
    "                durations.append(duration)\n",
    "                genres.append(genre)\n",
    "\n",
    "                # Add the title to the set of scraped titles to prevent duplicates\n",
    "                scraped_titles.add(title)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error while scraping the data:\", e)\n",
    "            continue\n",
    "\n",
    "    # Try to click the \"Load More\" button and increment counter\n",
    "    try:\n",
    "        # Find the \"Load More\" button (Next button)\n",
    "        next_button = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/div[2]/div/span')\n",
    "\n",
    "        # Perform the action to hover over and click the \"Load More\" button\n",
    "        ActionChains(driver).move_to_element(next_button).perform()\n",
    "        next_button.click()\n",
    "\n",
    "        # Increment the counter\n",
    "        load_more_count += 1\n",
    "\n",
    "        # Wait for 3 seconds to allow more movies to load\n",
    "        time.sleep(3)\n",
    "    except Exception as e:\n",
    "        print(\"Error in load more option\", e)\n",
    "        break  # Exit the loop if the button cannot be found or clicked\n",
    "\n",
    "# Close the browser after scraping\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame from the scraped data\n",
    "final_data_action = pd.DataFrame({\n",
    "    'Movie Title': movie_titles,\n",
    "    'Movie Rating': ratings,\n",
    "    'Movie Votings': votings,\n",
    "    'Movie Durations': durations,\n",
    "    'Genres': genres\n",
    "})\n",
    "\n",
    "# Save the data to a CSV file\n",
    "final_data_action.to_csv(r'D:\\DA\\IMDB_2024_sciencefiction.csv', index=False)\n",
    "\n",
    "print(\"Scraping finished and data saved to CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datafiles Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Adding CSV files based on Genres collection\n",
    "csv_files = ['IMDB_2024_action.csv', 'IMDB_2024_animation.csv', 'IMDB_2024_family.csv','IMDB_2024_fantacy.csv','IMDB_2024_sciencefiction.csv']  \n",
    "\n",
    "dataframes = []\n",
    "\n",
    "# Loop through the files/read data into dataframe\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('IMDB_2024_movies.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1850 entries, 0 to 1849\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Movie Title      1850 non-null   object \n",
      " 1   Movie Rating     1850 non-null   float64\n",
      " 2   Movie Votings    1850 non-null   object \n",
      " 3   Movie Durations  1850 non-null   object \n",
      " 4   Genres           1850 non-null   object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 72.4+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Votings column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to convert values\n",
    "def convert_to_int(value):\n",
    "    # Ensure the value is a string (if it's not already)\n",
    "    value = str(value).strip()\n",
    "    \n",
    "    # Remove any unwanted characters (like parentheses or extra spaces)\n",
    "    value = value.replace('(', '').replace(')', '').replace(' ', '')\n",
    "    \n",
    "    # Check if the value contains 'K' (thousands)\n",
    "    if 'K' in value:\n",
    "        # Remove 'K' and convert to float, then multiply by 1000\n",
    "        return abs(int(float(value.replace('K', '')) * 1000))\n",
    "    # If the value is negative, convert to positive integer\n",
    "    elif value.startswith('-'):\n",
    "        return abs(int(value))\n",
    "    # If the value is a float (e.g., '1.4'), convert it to float first and then to int\n",
    "    elif '.' in value:\n",
    "        return abs(int(float(value)))\n",
    "    # If no 'K' and it's a regular number, convert directly\n",
    "    else:\n",
    "        return abs(int(value))\n",
    "\n",
    "# Convert 'Movie Votings' column values\n",
    "merged_df['Movie Votings'] = merged_df['Movie Votings'].apply(convert_to_int)\n",
    "\n",
    "# Optionally, print the result\n",
    "# display(merged_df['Movie Votings'])\n",
    "\n",
    "# Update the csv file with the Cleaned Movie Votings\n",
    "# Save the merged DataFrame to a CSV file\n",
    "merged_df.to_csv('IMDB_2024_movies.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1850 entries, 0 to 1849\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Movie Title      1850 non-null   object \n",
      " 1   Movie Rating     1850 non-null   float64\n",
      " 2   Movie Votings    1850 non-null   int64  \n",
      " 3   Movie Durations  1850 non-null   object \n",
      " 4   Genres           1850 non-null   object \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 72.4+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the non duration values to duration based on average\n",
    "terms_to_replace = ['R', 'TV-Y7', 'Not Rated', '16+', 'TV-Y']\n",
    "\n",
    "merged_df['Movie Durations'] = merged_df['Movie Durations'].replace(terms_to_replace, '90m')\n",
    "merged_df.to_csv('IMDB_2024_movies.csv', index=False)\n",
    "\n",
    "# Print to check the updated dataframe\n",
    "#print(merged_df['Movie Durations'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to convert 'h' and 'm' format to total minutes\n",
    "def convert_to_minutes(duration):\n",
    "    # If the duration is in the format of '1h 44m'\n",
    "    match = re.match(r'(?:(\\d+)h)?(?:\\s*(\\d+)m)?', duration)\n",
    "    if match:\n",
    "        hours = match.group(1)  # Extract the hours\n",
    "        minutes = match.group(2)  # Extract the minutes\n",
    "        \n",
    "        # Convert hours to minutes and sum\n",
    "        total_minutes = 0\n",
    "        if hours:\n",
    "            total_minutes += int(hours) * 60\n",
    "        if minutes:\n",
    "            total_minutes += int(minutes)\n",
    "        \n",
    "        return total_minutes\n",
    "    return None  # In case the duration format is not recognized\n",
    "\n",
    "# Apply the conversion to the 'Movie Durations' column\n",
    "merged_df['Movie Durations'] = merged_df['Movie Durations'].apply(convert_to_minutes)\n",
    "\n",
    "# Save the updated dataframe to a CSV file\n",
    "merged_df.to_csv('IMDB_2024_movies.csv', index=False)\n",
    "\n",
    "# Print to check the updated dataframe\n",
    "#print(merged_df[['Movie Durations']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1850 entries, 0 to 1849\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Movie Title      1850 non-null   object \n",
      " 1   Movie Rating     1850 non-null   float64\n",
      " 2   Movie Votings    1850 non-null   int64  \n",
      " 3   Movie Durations  1850 non-null   int64  \n",
      " 4   Genres           1850 non-null   object \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 72.4+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database created successfully!\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "# Establish connection to the MySQL database in XAMPP\n",
    "connection = mysql.connector.connect(\n",
    "    host='localhost',       # XAMPP MySQL localhost\n",
    "    user='root',            # Default user for MySQL in XAMPP\n",
    "    password=''            # Default password for MySQL in XAMPP (usually empty)\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Create a new database\n",
    "cursor.execute(\"CREATE DATABASE IF NOT EXISTS imdb\")\n",
    "\n",
    "# Commit changes (though in this case, commit is optional)\n",
    "connection.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "print(\"Database created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully!\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "# Establish connection to the MySQL database in XAMPP\n",
    "connection = mysql.connector.connect(\n",
    "    host='localhost',       # XAMPP MySQL localhost\n",
    "    user='root',            # Default user for MySQL in XAMPP\n",
    "    password=''            # Default password for MySQL in XAMPP (usually empty)\n",
    ")\n",
    "# Create a cursor object to interact with the MySQL server\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Switch to the newly created database\n",
    "cursor.execute(\"USE imdb\")\n",
    "\n",
    "# Create a table named 'movies'\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS movies (\n",
    "        title VARCHAR(100),\n",
    "        rating FLOAT NOT NULL,\n",
    "        votings INT NOT NULL,\n",
    "        duration INT NOT NULL,\n",
    "        genres VARCHAR(100)\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Commit the changes\n",
    "connection.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "print(\"Table created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from CSV has been inserted into the users table successfully!\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import csv\n",
    "\n",
    "# Establish a connection to MySQL database\n",
    "connection = mysql.connector.connect(\n",
    "    host=\"localhost\",  \n",
    "    user=\"root\",  \n",
    "    password=\"\",  \n",
    "    database=\"imdb\" \n",
    ")\n",
    "\n",
    "# Create a cursor object to interact with the database\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Open and read the CSV file\n",
    "with open('IMDB_2024_movies.csv', mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)  # Skip the header row \n",
    "\n",
    "    # Iterate over the rows in the CSV file and insert them into the table\n",
    "    for row in csv_reader:\n",
    "        # Insert data into the movies table\n",
    "        cursor.execute('''\n",
    "            INSERT INTO movies (title, rating, votings, duration, genres)\n",
    "            VALUES (%s, %s, %s, %s,%s)\n",
    "        ''', (row[0], row[1], row[2], row[3],row[4]))  \n",
    "\n",
    "# Commit the transaction\n",
    "connection.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "print(\"Data from CSV has been inserted into the users table successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
